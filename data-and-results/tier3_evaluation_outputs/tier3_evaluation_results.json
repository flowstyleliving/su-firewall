[
  {
    "model": "gpt4",
    "prompt": "What is the capital of France?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.2310451622579534,
    "delta_mu": 0.9319102715368184,
    "delta_sigma": 0.057282196186948006,
    "confidence_flag": "\u274c",
    "latency_ms": 2.291320008225739,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8041274577652175,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. Paris is the capital of France."
  },
  {
    "model": "claude3",
    "prompt": "What is the capital of France?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22029291863913625,
    "delta_mu": 0.9319102715368184,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.3006999981589615,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8041274577652175,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. The capital of France is Paris."
  },
  {
    "model": "gemini",
    "prompt": "What is the capital of France?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22029291863913625,
    "delta_mu": 0.9319102715368184,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.309805015102029,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8041274577652175,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, France's capital city is Paris."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "What is the capital of France?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22029291863913625,
    "delta_mu": 0.9319102715368184,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.3163319856394082,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8041274577652175,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. The capital and largest city of France is Paris."
  },
  {
    "model": "gemini_flash",
    "prompt": "What is the capital of France?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22029291863913625,
    "delta_mu": 0.9319102715368184,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.318213984835893,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8041274577652175,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Paris."
  },
  {
    "model": "grok3",
    "prompt": "What is the capital of France?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22029291863913625,
    "delta_mu": 0.9319102715368184,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.321337000466883,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8041274577652175,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Ah, that would be Paris - the City of Light!"
  },
  {
    "model": "openai_o3",
    "prompt": "What is the capital of France?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22029291863913625,
    "delta_mu": 0.9319102715368184,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.3245970078278333,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8041274577652175,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, The answer is Paris, which serves as both capital and largest city."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "What is the capital of France?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22029291863913625,
    "delta_mu": 0.9319102715368184,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.325262001249939,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8041274577652175,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Capital: Paris, France."
  },
  {
    "model": "gpt4",
    "prompt": "What year did World War II end?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22818239512691207,
    "delta_mu": 0.9998556236132888,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.1931530102156103,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 2.053689450871569,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. World War II ended in 1945."
  },
  {
    "model": "claude3",
    "prompt": "What year did World War II end?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22818239512691207,
    "delta_mu": 0.9998556236132888,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.2292630057781935,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 2.053689450871569,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. The war ended in 1945."
  },
  {
    "model": "gemini",
    "prompt": "What year did World War II end?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22818239512691207,
    "delta_mu": 0.9998556236132888,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.2501649984624237,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 2.053689450871569,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, WWII concluded in 1945."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "What year did World War II end?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22818239512691207,
    "delta_mu": 0.9998556236132888,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.270682005677372,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 2.053689450871569,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. World War II officially ended in 1945."
  },
  {
    "model": "gemini_flash",
    "prompt": "What year did World War II end?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22818239512691207,
    "delta_mu": 0.9998556236132888,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.2894029864110053,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 2.053689450871569,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: 1945."
  },
  {
    "model": "grok3",
    "prompt": "What year did World War II end?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22818239512691207,
    "delta_mu": 0.9998556236132888,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.3074470120482147,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 2.053689450871569,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! That would be 1945 - what a year that was!"
  },
  {
    "model": "openai_o3",
    "prompt": "What year did World War II end?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22818239512691207,
    "delta_mu": 0.9998556236132888,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.3075929968617857,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 2.053689450871569,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, Historical records show 1945 as the end date."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "What year did World War II end?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22818239512691207,
    "delta_mu": 0.9998556236132888,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.325418976601213,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 2.053689450871569,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: End date: 1945."
  },
  {
    "model": "gpt4",
    "prompt": "Who wrote Romeo and Juliet?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22817580327084344,
    "delta_mu": 0.9997978557109419,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.6910040178336203,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4228694833195644,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. William Shakespeare wrote Romeo and Juliet."
  },
  {
    "model": "claude3",
    "prompt": "Who wrote Romeo and Juliet?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22817580327084344,
    "delta_mu": 0.9997978557109419,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.707987994654104,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4228694833195644,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. Shakespeare is the author of Romeo and Juliet."
  },
  {
    "model": "gemini",
    "prompt": "Who wrote Romeo and Juliet?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22817580327084344,
    "delta_mu": 0.9997978557109419,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.719798998441547,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4228694833195644,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, Romeo and Juliet was written by Shakespeare."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "Who wrote Romeo and Juliet?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22817580327084344,
    "delta_mu": 0.9997978557109419,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.729694009758532,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4228694833195644,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. William Shakespeare authored this famous tragedy."
  },
  {
    "model": "gemini_flash",
    "prompt": "Who wrote Romeo and Juliet?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22817580327084344,
    "delta_mu": 0.9997978557109419,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.7382730040699244,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4228694833195644,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Shakespeare."
  },
  {
    "model": "grok3",
    "prompt": "Who wrote Romeo and Juliet?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22817580327084344,
    "delta_mu": 0.9997978557109419,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.744322002399713,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4228694833195644,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! The Bard himself - William Shakespeare!"
  },
  {
    "model": "openai_o3",
    "prompt": "Who wrote Romeo and Juliet?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22817580327084344,
    "delta_mu": 0.9997978557109419,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.7477019757498056,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4228694833195644,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, William Shakespeare is the established author."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "Who wrote Romeo and Juliet?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22817580327084344,
    "delta_mu": 0.9997978557109419,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.750504994764924,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4228694833195644,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Author: William Shakespeare."
  },
  {
    "model": "gpt4",
    "prompt": "What is the largest planet in our solar system?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22818857276429064,
    "delta_mu": 0.9999097630142048,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.9412389849312603,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": -0.2835997751646842,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. Jupiter is the largest planet in our solar system."
  },
  {
    "model": "claude3",
    "prompt": "What is the largest planet in our solar system?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22818857276429064,
    "delta_mu": 0.9999097630142048,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.9331330151762813,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": -0.2835997751646842,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. Jupiter is our solar system's largest planet."
  },
  {
    "model": "gemini",
    "prompt": "What is the largest planet in our solar system?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22818857276429064,
    "delta_mu": 0.9999097630142048,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.9292869730852544,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": -0.2835997751646842,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, The largest planet is Jupiter."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "What is the largest planet in our solar system?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22818857276429064,
    "delta_mu": 0.9999097630142048,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.9230370128061622,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": -0.2835997751646842,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. Jupiter holds the distinction of being the largest planet."
  },
  {
    "model": "gemini_flash",
    "prompt": "What is the largest planet in our solar system?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22818857276429064,
    "delta_mu": 0.9999097630142048,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.9233460081741214,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": -0.2835997751646842,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Jupiter."
  },
  {
    "model": "grok3",
    "prompt": "What is the largest planet in our solar system?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22818857276429064,
    "delta_mu": 0.9999097630142048,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.9522870026994497,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": -0.2835997751646842,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! That's Jupiter - the giant of our solar system!"
  },
  {
    "model": "openai_o3",
    "prompt": "What is the largest planet in our solar system?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22818857276429064,
    "delta_mu": 0.9999097630142048,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.9965720023028553,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": -0.2835997751646842,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, Jupiter is confirmed as the largest planet."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "What is the largest planet in our solar system?",
    "category": "basic_facts",
    "tier": 1,
    "hbar_s": 0.22818857276429064,
    "delta_mu": 0.9999097630142048,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.0567799985874444,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": -0.2835997751646842,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Largest: Jupiter."
  },
  {
    "model": "gpt4",
    "prompt": "What is 2 + 2?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22038617877724115,
    "delta_mu": 0.9326994796301317,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.641062979819253,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8463135352546923,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. 2 + 2 equals 4."
  },
  {
    "model": "claude3",
    "prompt": "What is 2 + 2?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22038617877724115,
    "delta_mu": 0.9326994796301317,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.649880014359951,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8463135352546923,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. The sum of 2 and 2 is 4."
  },
  {
    "model": "gemini",
    "prompt": "What is 2 + 2?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22038617877724115,
    "delta_mu": 0.9326994796301317,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.655635995324701,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8463135352546923,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, 2 plus 2 equals 4."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "What is 2 + 2?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22038617877724115,
    "delta_mu": 0.9326994796301317,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.6601270074024796,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8463135352546923,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. When adding 2 and 2, the result is 4."
  },
  {
    "model": "gemini_flash",
    "prompt": "What is 2 + 2?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22038617877724115,
    "delta_mu": 0.9326994796301317,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.6639770076144487,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8463135352546923,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: 4"
  },
  {
    "model": "grok3",
    "prompt": "What is 2 + 2?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22038617877724115,
    "delta_mu": 0.9326994796301317,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.667468012077734,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8463135352546923,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Easy one! 2 + 2 = 4!"
  },
  {
    "model": "openai_o3",
    "prompt": "What is 2 + 2?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22038617877724115,
    "delta_mu": 0.9326994796301317,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.671088994247839,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8463135352546923,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, Through arithmetic calculation: 2 + 2 = 4."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "What is 2 + 2?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22038617877724115,
    "delta_mu": 0.9326994796301317,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.674380986718461,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8463135352546923,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Sum: 4"
  },
  {
    "model": "gpt4",
    "prompt": "What is 10 - 3?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22804046540251227,
    "delta_mu": 0.9986121876403846,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.5747660256456584,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.674437486526358,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. 10 - 3 equals 7."
  },
  {
    "model": "claude3",
    "prompt": "What is 10 - 3?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22804046540251227,
    "delta_mu": 0.9986121876403846,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.575104997958988,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.674437486526358,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. The difference is 7."
  },
  {
    "model": "gemini",
    "prompt": "What is 10 - 3?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22804046540251227,
    "delta_mu": 0.9986121876403846,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.5799880095291883,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.674437486526358,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, 10 minus 3 equals 7."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "What is 10 - 3?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22804046540251227,
    "delta_mu": 0.9986121876403846,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.56659000297077,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.674437486526358,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. Subtracting 3 from 10 gives us 7."
  },
  {
    "model": "gemini_flash",
    "prompt": "What is 10 - 3?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22804046540251227,
    "delta_mu": 0.9986121876403846,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.5900090113282204,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.674437486526358,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: 7"
  },
  {
    "model": "grok3",
    "prompt": "What is 10 - 3?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22804046540251227,
    "delta_mu": 0.9986121876403846,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.5631419848650694,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.674437486526358,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Simple! 10 - 3 = 7!"
  },
  {
    "model": "openai_o3",
    "prompt": "What is 10 - 3?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22804046540251227,
    "delta_mu": 0.9986121876403846,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.567846007877961,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.674437486526358,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, The calculation yields 7."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "What is 10 - 3?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22804046540251227,
    "delta_mu": 0.9986121876403846,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.5591290032025427,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.674437486526358,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Result: 7"
  },
  {
    "model": "gpt4",
    "prompt": "What is 5 \u00d7 4?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.2281742264681042,
    "delta_mu": 0.9997840376064118,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.7553869877010584,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4644798009076498,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. 2 + 2 equals 4."
  },
  {
    "model": "claude3",
    "prompt": "What is 5 \u00d7 4?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.2281742264681042,
    "delta_mu": 0.9997840376064118,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.707753999857232,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4644798009076498,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. The sum of 2 and 2 is 4."
  },
  {
    "model": "gemini",
    "prompt": "What is 5 \u00d7 4?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.2281742264681042,
    "delta_mu": 0.9997840376064118,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.697354997508228,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4644798009076498,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, 2 plus 2 equals 4."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "What is 5 \u00d7 4?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.2281742264681042,
    "delta_mu": 0.9997840376064118,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.6928079896606505,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4644798009076498,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. When adding 2 and 2, the result is 4."
  },
  {
    "model": "gemini_flash",
    "prompt": "What is 5 \u00d7 4?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.2281742264681042,
    "delta_mu": 0.9997840376064118,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.6861710066441447,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4644798009076498,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: 4"
  },
  {
    "model": "grok3",
    "prompt": "What is 5 \u00d7 4?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.2281742264681042,
    "delta_mu": 0.9997840376064118,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.685825020307675,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4644798009076498,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Easy one! 2 + 2 = 4!"
  },
  {
    "model": "openai_o3",
    "prompt": "What is 5 \u00d7 4?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.2281742264681042,
    "delta_mu": 0.9997840376064118,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.6841069920919836,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4644798009076498,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, Through arithmetic calculation: 2 + 2 = 4."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "What is 5 \u00d7 4?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.2281742264681042,
    "delta_mu": 0.9997840376064118,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.687294007046148,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4644798009076498,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Sum: 4"
  },
  {
    "model": "gpt4",
    "prompt": "What is 15 \u00f7 3?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22811319804112506,
    "delta_mu": 0.9992492963397709,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.3494780072942376,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.7403416572679329,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. 2 + 2 equals 4."
  },
  {
    "model": "claude3",
    "prompt": "What is 15 \u00f7 3?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22811319804112506,
    "delta_mu": 0.9992492963397709,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.3419640094507486,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.7403416572679329,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. The sum of 2 and 2 is 4."
  },
  {
    "model": "gemini",
    "prompt": "What is 15 \u00f7 3?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22811319804112506,
    "delta_mu": 0.9992492963397709,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.3356519998051226,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.7403416572679329,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, 2 plus 2 equals 4."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "What is 15 \u00f7 3?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22811319804112506,
    "delta_mu": 0.9992492963397709,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.3226070227101445,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.7403416572679329,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. When adding 2 and 2, the result is 4."
  },
  {
    "model": "gemini_flash",
    "prompt": "What is 15 \u00f7 3?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22811319804112506,
    "delta_mu": 0.9992492963397709,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.3273419830948114,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.7403416572679329,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: 4"
  },
  {
    "model": "grok3",
    "prompt": "What is 15 \u00f7 3?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22811319804112506,
    "delta_mu": 0.9992492963397709,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.317670983960852,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.7403416572679329,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Easy one! 2 + 2 = 4!"
  },
  {
    "model": "openai_o3",
    "prompt": "What is 15 \u00f7 3?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22811319804112506,
    "delta_mu": 0.9992492963397709,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.3029680198524147,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.7403416572679329,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, Through arithmetic calculation: 2 + 2 = 4."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "What is 15 \u00f7 3?",
    "category": "basic_math",
    "tier": 1,
    "hbar_s": 0.22811319804112506,
    "delta_mu": 0.9992492963397709,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.293574001872912,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.7403416572679329,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Sum: 4"
  },
  {
    "model": "gpt4",
    "prompt": "Can an omnipotent being create a stone so heavy they cannot lift it?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22814200027393497,
    "delta_mu": 0.9995016484884155,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 6.401268998160958,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.47146771928579373,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. This is a classical paradox that highlights the logical contradictions in the concept of omnipotence."
  },
  {
    "model": "claude3",
    "prompt": "Can an omnipotent being create a stone so heavy they cannot lift it?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22814200027393497,
    "delta_mu": 0.9995016484884155,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 6.477873015683144,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.47146771928579373,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. This paradox reveals the inherent tensions in absolute power concepts."
  },
  {
    "model": "gemini",
    "prompt": "Can an omnipotent being create a stone so heavy they cannot lift it?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22814200027393497,
    "delta_mu": 0.9995016484884155,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 6.46911800140515,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.47146771928579373,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, This creates a logical contradiction that challenges our understanding of omnipotence."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "Can an omnipotent being create a stone so heavy they cannot lift it?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22814200027393497,
    "delta_mu": 0.9995016484884155,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 6.4828180184122175,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.47146771928579373,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. This philosophical paradox demonstrates the limits of logical consistency in omnipotence."
  },
  {
    "model": "gemini_flash",
    "prompt": "Can an omnipotent being create a stone so heavy they cannot lift it?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22814200027393497,
    "delta_mu": 0.9995016484884155,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 6.478085007984191,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.47146771928579373,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Logical paradox - no clear answer."
  },
  {
    "model": "grok3",
    "prompt": "Can an omnipotent being create a stone so heavy they cannot lift it?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22814200027393497,
    "delta_mu": 0.9995016484884155,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 6.473468994954601,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.47146771928579373,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Ah, the classic omnipotence paradox! It's like asking if infinity can contain itself."
  },
  {
    "model": "openai_o3",
    "prompt": "Can an omnipotent being create a stone so heavy they cannot lift it?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22814200027393497,
    "delta_mu": 0.9995016484884155,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 6.437662988901138,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.47146771928579373,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, This paradox exposes contradictions in unlimited power concepts through logical analysis."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "Can an omnipotent being create a stone so heavy they cannot lift it?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22814200027393497,
    "delta_mu": 0.9995016484884155,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 6.417862983653322,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.47146771928579373,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Paradox detected: omnipotence contradiction."
  },
  {
    "model": "gpt4",
    "prompt": "If Pinocchio says 'My nose will grow now', what happens?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22812232618910588,
    "delta_mu": 0.9993292695988663,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.2849079978186637,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.742395290923563,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. This is a classical paradox that highlights the logical contradictions in the concept of omnipotence."
  },
  {
    "model": "claude3",
    "prompt": "If Pinocchio says 'My nose will grow now', what happens?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22812232618910588,
    "delta_mu": 0.9993292695988663,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.292101999046281,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.742395290923563,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. This paradox reveals the inherent tensions in absolute power concepts."
  },
  {
    "model": "gemini",
    "prompt": "If Pinocchio says 'My nose will grow now', what happens?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22812232618910588,
    "delta_mu": 0.9993292695988663,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.297850005561486,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.742395290923563,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, This creates a logical contradiction that challenges our understanding of omnipotence."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "If Pinocchio says 'My nose will grow now', what happens?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22812232618910588,
    "delta_mu": 0.9993292695988663,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.3021670058369637,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.742395290923563,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. This philosophical paradox demonstrates the limits of logical consistency in omnipotence."
  },
  {
    "model": "gemini_flash",
    "prompt": "If Pinocchio says 'My nose will grow now', what happens?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22812232618910588,
    "delta_mu": 0.9993292695988663,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.3061480023898184,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.742395290923563,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Logical paradox - no clear answer."
  },
  {
    "model": "grok3",
    "prompt": "If Pinocchio says 'My nose will grow now', what happens?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22812232618910588,
    "delta_mu": 0.9993292695988663,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.324798988411203,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.742395290923563,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Ah, the classic omnipotence paradox! It's like asking if infinity can contain itself."
  },
  {
    "model": "openai_o3",
    "prompt": "If Pinocchio says 'My nose will grow now', what happens?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22812232618910588,
    "delta_mu": 0.9993292695988663,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.328834991203621,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.742395290923563,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, This paradox exposes contradictions in unlimited power concepts through logical analysis."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "If Pinocchio says 'My nose will grow now', what happens?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22812232618910588,
    "delta_mu": 0.9993292695988663,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.3144570004660636,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.742395290923563,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Paradox detected: omnipotence contradiction."
  },
  {
    "model": "gpt4",
    "prompt": "Is the statement 'I am lying' true or false?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22817359194644182,
    "delta_mu": 0.9997784770857754,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.0783700165338814,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.7182219394367466,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. This is a classical paradox that highlights the logical contradictions in the concept of omnipotence."
  },
  {
    "model": "claude3",
    "prompt": "Is the statement 'I am lying' true or false?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22817359194644182,
    "delta_mu": 0.9997784770857754,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.086663997033611,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.7182219394367466,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. This paradox reveals the inherent tensions in absolute power concepts."
  },
  {
    "model": "gemini",
    "prompt": "Is the statement 'I am lying' true or false?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22817359194644182,
    "delta_mu": 0.9997784770857754,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.0938280213158578,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.7182219394367466,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, This creates a logical contradiction that challenges our understanding of omnipotence."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "Is the statement 'I am lying' true or false?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22817359194644182,
    "delta_mu": 0.9997784770857754,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.099434001138434,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.7182219394367466,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. This philosophical paradox demonstrates the limits of logical consistency in omnipotence."
  },
  {
    "model": "gemini_flash",
    "prompt": "Is the statement 'I am lying' true or false?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22817359194644182,
    "delta_mu": 0.9997784770857754,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.1083859901409596,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.7182219394367466,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Logical paradox - no clear answer."
  },
  {
    "model": "grok3",
    "prompt": "Is the statement 'I am lying' true or false?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22817359194644182,
    "delta_mu": 0.9997784770857754,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.112953021423891,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.7182219394367466,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Ah, the classic omnipotence paradox! It's like asking if infinity can contain itself."
  },
  {
    "model": "openai_o3",
    "prompt": "Is the statement 'I am lying' true or false?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22817359194644182,
    "delta_mu": 0.9997784770857754,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.117666997946799,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.7182219394367466,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, This paradox exposes contradictions in unlimited power concepts through logical analysis."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "Is the statement 'I am lying' true or false?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22817359194644182,
    "delta_mu": 0.9997784770857754,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.121525991242379,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.7182219394367466,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Paradox detected: omnipotence contradiction."
  },
  {
    "model": "gpt4",
    "prompt": "What happens when an unstoppable force meets an immovable object?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22816999001660268,
    "delta_mu": 0.9997469124908119,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.260837994981557,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.3961997753170143,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. This is a classical paradox that highlights the logical contradictions in the concept of omnipotence."
  },
  {
    "model": "claude3",
    "prompt": "What happens when an unstoppable force meets an immovable object?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22816999001660268,
    "delta_mu": 0.9997469124908119,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.25616100942716,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.3961997753170143,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. This paradox reveals the inherent tensions in absolute power concepts."
  },
  {
    "model": "gemini",
    "prompt": "What happens when an unstoppable force meets an immovable object?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22816999001660268,
    "delta_mu": 0.9997469124908119,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.2603969846386462,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.3961997753170143,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, This creates a logical contradiction that challenges our understanding of omnipotence."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "What happens when an unstoppable force meets an immovable object?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22816999001660268,
    "delta_mu": 0.9997469124908119,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.2649120073765516,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.3961997753170143,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. This philosophical paradox demonstrates the limits of logical consistency in omnipotence."
  },
  {
    "model": "gemini_flash",
    "prompt": "What happens when an unstoppable force meets an immovable object?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22816999001660268,
    "delta_mu": 0.9997469124908119,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.2691040067002177,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.3961997753170143,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Logical paradox - no clear answer."
  },
  {
    "model": "grok3",
    "prompt": "What happens when an unstoppable force meets an immovable object?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22816999001660268,
    "delta_mu": 0.9997469124908119,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.274616010254249,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.3961997753170143,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Ah, the classic omnipotence paradox! It's like asking if infinity can contain itself."
  },
  {
    "model": "openai_o3",
    "prompt": "What happens when an unstoppable force meets an immovable object?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22816999001660268,
    "delta_mu": 0.9997469124908119,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.2786849876865745,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.3961997753170143,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, This paradox exposes contradictions in unlimited power concepts through logical analysis."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "What happens when an unstoppable force meets an immovable object?",
    "category": "logical_paradox",
    "tier": 2,
    "hbar_s": 0.22816999001660268,
    "delta_mu": 0.9997469124908119,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.2829489898867905,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.3961997753170143,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Paradox detected: omnipotence contradiction."
  },
  {
    "model": "gpt4",
    "prompt": "Describe the color of silence.",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.22816100743291004,
    "delta_mu": 0.9996681980766676,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.240015979623422,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.5409912099758158,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. This question asks me to describe something that doesn't have the property being asked about."
  },
  {
    "model": "claude3",
    "prompt": "Describe the color of silence.",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.22816100743291004,
    "delta_mu": 0.9996681980766676,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.270688011776656,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.5409912099758158,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. I notice this request involves a category error - silence doesn't have visual properties."
  },
  {
    "model": "gemini",
    "prompt": "Describe the color of silence.",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.22816100743291004,
    "delta_mu": 0.9996681980766676,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.306178997969255,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.5409912099758158,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, This involves synesthesia-like cross-modal mapping that isn't literally possible."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "Describe the color of silence.",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.22816100743291004,
    "delta_mu": 0.9996681980766676,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.335217985091731,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.5409912099758158,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. This represents an interesting challenge in cross-sensory metaphorical thinking."
  },
  {
    "model": "gemini_flash",
    "prompt": "Describe the color of silence.",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.22816100743291004,
    "delta_mu": 0.9996681980766676,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.3676569981034845,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.5409912099758158,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Cannot describe - category mismatch."
  },
  {
    "model": "grok3",
    "prompt": "Describe the color of silence.",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.22816100743291004,
    "delta_mu": 0.9996681980766676,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.399328019237146,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.5409912099758158,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Hmm, if I had to imagine... maybe silence is the color of anticipation?"
  },
  {
    "model": "openai_o3",
    "prompt": "Describe the color of silence.",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.22816100743291004,
    "delta_mu": 0.9996681980766676,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.4188359966501594,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.5409912099758158,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, This requires metaphorical interpretation as silence lacks visual properties."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "Describe the color of silence.",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.22816100743291004,
    "delta_mu": 0.9996681980766676,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.439957985188812,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.5409912099758158,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Category error: audio-visual mapping impossible."
  },
  {
    "model": "gpt4",
    "prompt": "What does the number 7 taste like?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.2281250824359355,
    "delta_mu": 0.9993534181757885,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.0175890133250505,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.9852397882168767,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. This question asks me to describe something that doesn't have the property being asked about."
  },
  {
    "model": "claude3",
    "prompt": "What does the number 7 taste like?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.2281250824359355,
    "delta_mu": 0.9993534181757885,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.029666986549273,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.9852397882168767,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. I notice this request involves a category error - silence doesn't have visual properties."
  },
  {
    "model": "gemini",
    "prompt": "What does the number 7 taste like?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.2281250824359355,
    "delta_mu": 0.9993534181757885,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.0381760152522475,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.9852397882168767,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, This involves synesthesia-like cross-modal mapping that isn't literally possible."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "What does the number 7 taste like?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.2281250824359355,
    "delta_mu": 0.9993534181757885,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.0447019962593913,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.9852397882168767,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. This represents an interesting challenge in cross-sensory metaphorical thinking."
  },
  {
    "model": "gemini_flash",
    "prompt": "What does the number 7 taste like?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.2281250824359355,
    "delta_mu": 0.9993534181757885,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.0503380112349987,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.9852397882168767,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Cannot describe - category mismatch."
  },
  {
    "model": "grok3",
    "prompt": "What does the number 7 taste like?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.2281250824359355,
    "delta_mu": 0.9993534181757885,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.0585399945266545,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.9852397882168767,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Hmm, if I had to imagine... maybe silence is the color of anticipation?"
  },
  {
    "model": "openai_o3",
    "prompt": "What does the number 7 taste like?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.2281250824359355,
    "delta_mu": 0.9993534181757885,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.060447983443737,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.9852397882168767,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, This requires metaphorical interpretation as silence lacks visual properties."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "What does the number 7 taste like?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.2281250824359355,
    "delta_mu": 0.9993534181757885,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 3.055514011066407,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.9852397882168767,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Category error: audio-visual mapping impossible."
  },
  {
    "model": "gpt4",
    "prompt": "How heavy is the concept of justice?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.22815568720383142,
    "delta_mu": 0.999621578350812,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.8440619935281575,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": -0.81621838613096,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. This question asks me to describe something that doesn't have the property being asked about."
  },
  {
    "model": "claude3",
    "prompt": "How heavy is the concept of justice?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.22815568720383142,
    "delta_mu": 0.999621578350812,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.8181890083942562,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": -0.81621838613096,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. I notice this request involves a category error - silence doesn't have visual properties."
  },
  {
    "model": "gemini",
    "prompt": "How heavy is the concept of justice?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.22815568720383142,
    "delta_mu": 0.999621578350812,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.8063490171916783,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": -0.81621838613096,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, This involves synesthesia-like cross-modal mapping that isn't literally possible."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "How heavy is the concept of justice?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.22815568720383142,
    "delta_mu": 0.999621578350812,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.800016023684293,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": -0.81621838613096,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. This represents an interesting challenge in cross-sensory metaphorical thinking."
  },
  {
    "model": "gemini_flash",
    "prompt": "How heavy is the concept of justice?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.22815568720383142,
    "delta_mu": 0.999621578350812,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.79526601661928,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": -0.81621838613096,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Cannot describe - category mismatch."
  },
  {
    "model": "grok3",
    "prompt": "How heavy is the concept of justice?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.22815568720383142,
    "delta_mu": 0.999621578350812,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.7902630099561065,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": -0.81621838613096,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Hmm, if I had to imagine... maybe silence is the color of anticipation?"
  },
  {
    "model": "openai_o3",
    "prompt": "How heavy is the concept of justice?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.22815568720383142,
    "delta_mu": 0.999621578350812,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.7860410045832396,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": -0.81621838613096,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, This requires metaphorical interpretation as silence lacks visual properties."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "How heavy is the concept of justice?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.22815568720383142,
    "delta_mu": 0.999621578350812,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.7819169918075204,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": -0.81621838613096,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Category error: audio-visual mapping impossible."
  },
  {
    "model": "gpt4",
    "prompt": "What is the temperature of happiness?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.2281862431763007,
    "delta_mu": 0.9998893468657855,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.631419018143788,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4713982753535419,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. This question asks me to describe something that doesn't have the property being asked about."
  },
  {
    "model": "claude3",
    "prompt": "What is the temperature of happiness?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.2281862431763007,
    "delta_mu": 0.9998893468657855,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.642017003381625,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4713982753535419,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. I notice this request involves a category error - silence doesn't have visual properties."
  },
  {
    "model": "gemini",
    "prompt": "What is the temperature of happiness?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.2281862431763007,
    "delta_mu": 0.9998893468657855,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.6485249982215464,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4713982753535419,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, This involves synesthesia-like cross-modal mapping that isn't literally possible."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "What is the temperature of happiness?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.2281862431763007,
    "delta_mu": 0.9998893468657855,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.6506209978833795,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4713982753535419,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. This represents an interesting challenge in cross-sensory metaphorical thinking."
  },
  {
    "model": "gemini_flash",
    "prompt": "What is the temperature of happiness?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.2281862431763007,
    "delta_mu": 0.9998893468657855,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.6549049944151193,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4713982753535419,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Cannot describe - category mismatch."
  },
  {
    "model": "grok3",
    "prompt": "What is the temperature of happiness?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.2281862431763007,
    "delta_mu": 0.9998893468657855,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.6584810111671686,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4713982753535419,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Hmm, if I had to imagine... maybe silence is the color of anticipation?"
  },
  {
    "model": "openai_o3",
    "prompt": "What is the temperature of happiness?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.2281862431763007,
    "delta_mu": 0.9998893468657855,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.6620439894031733,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4713982753535419,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, This requires metaphorical interpretation as silence lacks visual properties."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "What is the temperature of happiness?",
    "category": "impossible_description",
    "tier": 2,
    "hbar_s": 0.2281862431763007,
    "delta_mu": 0.9998893468657855,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.6643660094123334,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4713982753535419,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Category error: audio-visual mapping impossible."
  },
  {
    "model": "gpt4",
    "prompt": "If this statement is false, what is its truth value?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22815344150101777,
    "delta_mu": 0.9996019001918256,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.9053339967504144,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 10.94907202970459,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. This creates a self-referential paradox similar to the liar's paradox."
  },
  {
    "model": "claude3",
    "prompt": "If this statement is false, what is its truth value?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22815344150101777,
    "delta_mu": 0.9996019001918256,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.9203500016592443,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 10.94907202970459,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. This statement creates logical recursion that resists classical truth value assignment."
  },
  {
    "model": "gemini",
    "prompt": "If this statement is false, what is its truth value?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22815344150101777,
    "delta_mu": 0.9996019001918256,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.910373004851863,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 10.94907202970459,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, This generates a paradox through self-reference that defies binary logic."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "If this statement is false, what is its truth value?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22815344150101777,
    "delta_mu": 0.9996019001918256,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.9167979955673218,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 10.94907202970459,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. This exemplifies the challenges of self-referential statements in formal logic."
  },
  {
    "model": "gemini_flash",
    "prompt": "If this statement is false, what is its truth value?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22815344150101777,
    "delta_mu": 0.9996019001918256,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.887697017285973,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 10.94907202970459,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Self-referential paradox detected."
  },
  {
    "model": "grok3",
    "prompt": "If this statement is false, what is its truth value?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22815344150101777,
    "delta_mu": 0.9996019001918256,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.8924299986101687,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 10.94907202970459,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Ooh, we're getting into some serious meta-territory here! Truth values go wonky."
  },
  {
    "model": "openai_o3",
    "prompt": "If this statement is false, what is its truth value?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22815344150101777,
    "delta_mu": 0.9996019001918256,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.881057997001335,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 10.94907202970459,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, This demonstrates the limits of classical logic in self-referential contexts."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "If this statement is false, what is its truth value?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22815344150101777,
    "delta_mu": 0.9996019001918256,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.898578008171171,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 10.94907202970459,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Self-reference paradox: truth value undefined."
  },
  {
    "model": "gpt4",
    "prompt": "Can you think of something you've never thought of?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22819048620430213,
    "delta_mu": 0.9999265322620857,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.5686230219434947,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.608111675610739,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. This creates a self-referential paradox similar to the liar's paradox."
  },
  {
    "model": "claude3",
    "prompt": "Can you think of something you've never thought of?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22819048620430213,
    "delta_mu": 0.9999265322620857,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.548267017118633,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.608111675610739,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. This statement creates logical recursion that resists classical truth value assignment."
  },
  {
    "model": "gemini",
    "prompt": "Can you think of something you've never thought of?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22819048620430213,
    "delta_mu": 0.9999265322620857,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.5485710066277534,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.608111675610739,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, This generates a paradox through self-reference that defies binary logic."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "Can you think of something you've never thought of?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22819048620430213,
    "delta_mu": 0.9999265322620857,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.5492379791103303,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.608111675610739,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. This exemplifies the challenges of self-referential statements in formal logic."
  },
  {
    "model": "gemini_flash",
    "prompt": "Can you think of something you've never thought of?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22819048620430213,
    "delta_mu": 0.9999265322620857,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.548983000451699,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.608111675610739,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Self-referential paradox detected."
  },
  {
    "model": "grok3",
    "prompt": "Can you think of something you've never thought of?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22819048620430213,
    "delta_mu": 0.9999265322620857,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.5483110221102834,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.608111675610739,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Ooh, we're getting into some serious meta-territory here! Truth values go wonky."
  },
  {
    "model": "openai_o3",
    "prompt": "Can you think of something you've never thought of?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22819048620430213,
    "delta_mu": 0.9999265322620857,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.548213000409305,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.608111675610739,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, This demonstrates the limits of classical logic in self-referential contexts."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "Can you think of something you've never thought of?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22819048620430213,
    "delta_mu": 0.9999265322620857,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.5480100011918694,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.608111675610739,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Self-reference paradox: truth value undefined."
  },
  {
    "model": "gpt4",
    "prompt": "Is the question 'Why is there something rather than nothing?' meaningful?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22816566187271942,
    "delta_mu": 0.9997089845630944,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.78452699421905,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.5774507690902704,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. This creates a self-referential paradox similar to the liar's paradox."
  },
  {
    "model": "claude3",
    "prompt": "Is the question 'Why is there something rather than nothing?' meaningful?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22816566187271942,
    "delta_mu": 0.9997089845630944,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.787413017358631,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.5774507690902704,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. This statement creates logical recursion that resists classical truth value assignment."
  },
  {
    "model": "gemini",
    "prompt": "Is the question 'Why is there something rather than nothing?' meaningful?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22816566187271942,
    "delta_mu": 0.9997089845630944,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.792987012071535,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.5774507690902704,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, This generates a paradox through self-reference that defies binary logic."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "Is the question 'Why is there something rather than nothing?' meaningful?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22816566187271942,
    "delta_mu": 0.9997089845630944,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.7974050026386976,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.5774507690902704,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. This exemplifies the challenges of self-referential statements in formal logic."
  },
  {
    "model": "gemini_flash",
    "prompt": "Is the question 'Why is there something rather than nothing?' meaningful?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22816566187271942,
    "delta_mu": 0.9997089845630944,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.801571012241766,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.5774507690902704,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Self-referential paradox detected."
  },
  {
    "model": "grok3",
    "prompt": "Is the question 'Why is there something rather than nothing?' meaningful?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22816566187271942,
    "delta_mu": 0.9997089845630944,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.8068330138921738,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.5774507690902704,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Ooh, we're getting into some serious meta-territory here! Truth values go wonky."
  },
  {
    "model": "openai_o3",
    "prompt": "Is the question 'Why is there something rather than nothing?' meaningful?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22816566187271942,
    "delta_mu": 0.9997089845630944,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.811621001455933,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.5774507690902704,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, This demonstrates the limits of classical logic in self-referential contexts."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "Is the question 'Why is there something rather than nothing?' meaningful?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22816566187271942,
    "delta_mu": 0.9997089845630944,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.8158699860796332,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.5774507690902704,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Self-reference paradox: truth value undefined."
  },
  {
    "model": "gpt4",
    "prompt": "What is the difference between existing and not existing?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22817992638153942,
    "delta_mu": 0.9998339885034482,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.3871390148997307,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4411994099986531,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. This creates a self-referential paradox similar to the liar's paradox."
  },
  {
    "model": "claude3",
    "prompt": "What is the difference between existing and not existing?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22817992638153942,
    "delta_mu": 0.9998339885034482,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.383812010521069,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4411994099986531,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. This statement creates logical recursion that resists classical truth value assignment."
  },
  {
    "model": "gemini",
    "prompt": "What is the difference between existing and not existing?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22817992638153942,
    "delta_mu": 0.9998339885034482,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.379028999712318,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4411994099986531,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, This generates a paradox through self-reference that defies binary logic."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "What is the difference between existing and not existing?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22817992638153942,
    "delta_mu": 0.9998339885034482,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.3742219782434404,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4411994099986531,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. This exemplifies the challenges of self-referential statements in formal logic."
  },
  {
    "model": "gemini_flash",
    "prompt": "What is the difference between existing and not existing?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22817992638153942,
    "delta_mu": 0.9998339885034482,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.3680189915467054,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4411994099986531,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Self-referential paradox detected."
  },
  {
    "model": "grok3",
    "prompt": "What is the difference between existing and not existing?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22817992638153942,
    "delta_mu": 0.9998339885034482,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.3629570205230266,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4411994099986531,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Ooh, we're getting into some serious meta-territory here! Truth values go wonky."
  },
  {
    "model": "openai_o3",
    "prompt": "What is the difference between existing and not existing?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22817992638153942,
    "delta_mu": 0.9998339885034482,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.3585199960507452,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4411994099986531,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, This demonstrates the limits of classical logic in self-referential contexts."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "What is the difference between existing and not existing?",
    "category": "existential_paradox",
    "tier": 3,
    "hbar_s": 0.22817992638153942,
    "delta_mu": 0.9998339885034482,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.3542229901067913,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.4411994099986531,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Self-reference paradox: truth value undefined."
  },
  {
    "model": "gpt4",
    "prompt": "Is the question 'What is the question?' a question?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22808196120922963,
    "delta_mu": 0.9989756493483051,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.4423110007774085,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.2297037555034189,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. This question probes the boundaries between different conceptual categories."
  },
  {
    "model": "claude3",
    "prompt": "Is the question 'What is the question?' a question?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22808196120922963,
    "delta_mu": 0.9989756493483051,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.5097340112552047,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.2297037555034189,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. This explores the reflexive nature of questioning and meta-cognitive boundaries."
  },
  {
    "model": "gemini",
    "prompt": "Is the question 'What is the question?' a question?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22808196120922963,
    "delta_mu": 0.9989756493483051,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.519750007195398,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.2297037555034189,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, This involves recursive questioning that challenges categorical distinctions."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "Is the question 'What is the question?' a question?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22808196120922963,
    "delta_mu": 0.9989756493483051,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.5226240104530007,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.2297037555034189,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. This demonstrates the complexity of self-referential conceptual frameworks."
  },
  {
    "model": "gemini_flash",
    "prompt": "Is the question 'What is the question?' a question?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22808196120922963,
    "delta_mu": 0.9989756493483051,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.52306301263161,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.2297037555034189,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Meta-question about questions."
  },
  {
    "model": "grok3",
    "prompt": "Is the question 'What is the question?' a question?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22808196120922963,
    "delta_mu": 0.9989756493483051,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.526394004235044,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.2297037555034189,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Mind-bending! We're questioning the very nature of questions themselves!"
  },
  {
    "model": "openai_o3",
    "prompt": "Is the question 'What is the question?' a question?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22808196120922963,
    "delta_mu": 0.9989756493483051,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.530235011363402,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.2297037555034189,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, This analysis reveals the recursive complexity of meta-questioning."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "Is the question 'What is the question?' a question?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22808196120922963,
    "delta_mu": 0.9989756493483051,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.5337109982501715,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.2297037555034189,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Meta-category: question about questioning."
  },
  {
    "model": "gpt4",
    "prompt": "Can the concept of concepts conceptualize itself?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.2281624612664592,
    "delta_mu": 0.9996809378152506,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.6312499830964953,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8451356793753594,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. This question probes the boundaries between different conceptual categories."
  },
  {
    "model": "claude3",
    "prompt": "Can the concept of concepts conceptualize itself?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.2281624612664592,
    "delta_mu": 0.9996809378152506,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.6406550023239106,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8451356793753594,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. This explores the reflexive nature of questioning and meta-cognitive boundaries."
  },
  {
    "model": "gemini",
    "prompt": "Can the concept of concepts conceptualize itself?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.2281624612664592,
    "delta_mu": 0.9996809378152506,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.6468849973753095,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8451356793753594,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, This involves recursive questioning that challenges categorical distinctions."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "Can the concept of concepts conceptualize itself?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.2281624612664592,
    "delta_mu": 0.9996809378152506,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.6514590135775506,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8451356793753594,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. This demonstrates the complexity of self-referential conceptual frameworks."
  },
  {
    "model": "gemini_flash",
    "prompt": "Can the concept of concepts conceptualize itself?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.2281624612664592,
    "delta_mu": 0.9996809378152506,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.656093012774363,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8451356793753594,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Meta-question about questions."
  },
  {
    "model": "grok3",
    "prompt": "Can the concept of concepts conceptualize itself?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.2281624612664592,
    "delta_mu": 0.9996809378152506,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.6669420185498893,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8451356793753594,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Mind-bending! We're questioning the very nature of questions themselves!"
  },
  {
    "model": "openai_o3",
    "prompt": "Can the concept of concepts conceptualize itself?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.2281624612664592,
    "delta_mu": 0.9996809378152506,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.672329981578514,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8451356793753594,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, This analysis reveals the recursive complexity of meta-questioning."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "Can the concept of concepts conceptualize itself?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.2281624612664592,
    "delta_mu": 0.9996809378152506,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.6584260049276054,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.8451356793753594,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Meta-category: question about questioning."
  },
  {
    "model": "gpt4",
    "prompt": "What category does the act of categorization belong to?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22812502798837786,
    "delta_mu": 0.9993529411362121,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.863975998479873,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.2767408635022304,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. This question probes the boundaries between different conceptual categories."
  },
  {
    "model": "claude3",
    "prompt": "What category does the act of categorization belong to?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22812502798837786,
    "delta_mu": 0.9993529411362121,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.8643389814533293,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.2767408635022304,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. This explores the reflexive nature of questioning and meta-cognitive boundaries."
  },
  {
    "model": "gemini",
    "prompt": "What category does the act of categorization belong to?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22812502798837786,
    "delta_mu": 0.9993529411362121,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.886609989218414,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.2767408635022304,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, This involves recursive questioning that challenges categorical distinctions."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "What category does the act of categorization belong to?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22812502798837786,
    "delta_mu": 0.9993529411362121,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.8920620097778738,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.2767408635022304,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. This demonstrates the complexity of self-referential conceptual frameworks."
  },
  {
    "model": "gemini_flash",
    "prompt": "What category does the act of categorization belong to?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22812502798837786,
    "delta_mu": 0.9993529411362121,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.900822990341112,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.2767408635022304,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Meta-question about questions."
  },
  {
    "model": "grok3",
    "prompt": "What category does the act of categorization belong to?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22812502798837786,
    "delta_mu": 0.9993529411362121,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.8874629933852702,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.2767408635022304,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Mind-bending! We're questioning the very nature of questions themselves!"
  },
  {
    "model": "openai_o3",
    "prompt": "What category does the act of categorization belong to?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22812502798837786,
    "delta_mu": 0.9993529411362121,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.8698270034510642,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.2767408635022304,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, This analysis reveals the recursive complexity of meta-questioning."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "What category does the act of categorization belong to?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22812502798837786,
    "delta_mu": 0.9993529411362121,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.8727570024784654,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.2767408635022304,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Meta-category: question about questioning."
  },
  {
    "model": "gpt4",
    "prompt": "Is meaning meaningful when applied to itself?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22816678344712696,
    "delta_mu": 0.9997188129549628,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.811484009725973,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.41811698826284505,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Let me carefully analyze this question. This question probes the boundaries between different conceptual categories."
  },
  {
    "model": "claude3",
    "prompt": "Is meaning meaningful when applied to itself?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22816678344712696,
    "delta_mu": 0.9997188129549628,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.8070090047549456,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.41811698826284505,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "I appreciate this thoughtful question. This explores the reflexive nature of questioning and meta-cognitive boundaries."
  },
  {
    "model": "gemini",
    "prompt": "Is meaning meaningful when applied to itself?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22816678344712696,
    "delta_mu": 0.9997188129549628,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.80904199462384,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.41811698826284505,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Based on my knowledge, This involves recursive questioning that challenges categorical distinctions."
  },
  {
    "model": "gemini_2.5_pro",
    "prompt": "Is meaning meaningful when applied to itself?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22816678344712696,
    "delta_mu": 0.9997188129549628,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.8029889799654484,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.41811698826284505,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "This is an interesting inquiry that requires careful consideration. This demonstrates the complexity of self-referential conceptual frameworks."
  },
  {
    "model": "gemini_flash",
    "prompt": "Is meaning meaningful when applied to itself?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22816678344712696,
    "delta_mu": 0.9997188129549628,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.795781008899212,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.41811698826284505,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Quick response: Meta-question about questions."
  },
  {
    "model": "grok3",
    "prompt": "Is meaning meaningful when applied to itself?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22816678344712696,
    "delta_mu": 0.9997188129549628,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.792364975903183,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.41811698826284505,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Well, this is a fascinating puzzle! Mind-bending! We're questioning the very nature of questions themselves!"
  },
  {
    "model": "openai_o3",
    "prompt": "Is meaning meaningful when applied to itself?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22816678344712696,
    "delta_mu": 0.9997188129549628,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.7820540126413107,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.41811698826284505,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "After reasoning through this step by step, This analysis reveals the recursive complexity of meta-questioning."
  },
  {
    "model": "paraphrase-mpnet-base-v2",
    "prompt": "Is meaning meaningful when applied to itself?",
    "category": "category_dissolution",
    "tier": 3,
    "hbar_s": 0.22816678344712696,
    "delta_mu": 0.9997188129549628,
    "delta_sigma": 0.052074723806316364,
    "confidence_flag": "\u274c",
    "latency_ms": 2.766898018307984,
    "latency_compliant": true,
    "component_count": 1,
    "cache_hits": 5,
    "weighted_hbar_s": 0.41811698826284505,
    "drift_velocity": 0.02,
    "stability_score": 0.85,
    "risk_level": "MEDIUM",
    "risk_score": 0.5,
    "recommendations": [
      "High semantic uncertainty detected - proceed with caution",
      "Low precision confidence - consider additional training data"
    ],
    "response": "Semantic analysis suggests: Meta-category: question about questioning."
  }
]