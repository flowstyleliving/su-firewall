{
  "default_model_id": "mistral-7b",
  "models": [
    {
      "context_len": 32000,
      "display_name": "Mixtral-8x7B (Apache-2.0)",
      "failure_law": {
        "lambda": 0.1,
        "tau": 0.3
      },
      "hf_repo": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "id": "mixtral-8x7b",
      "notes": "MoE SOTA; use router logits optionally",
      "quant": "4bit-ok"
    },
    {
      "context_len": 32000,
      "display_name": "Mistral-7B (Apache-2.0)",
      "failure_law": {
        "lambda": 0.1,
        "last_optimized": "2025-08-17T11:03:28.024602+00:00",
        "tau": 1.115
      },
      "calibration_mode": {
        "type": "Pragmatic",
        "scaling": "EmpiricalGolden",
        "abort_threshold": 2.5,
        "warn_threshold": 4.0,
        "proceed_threshold": 6.0
      },
      "hf_repo": "mistralai/Mistral-7B-Instruct-v0.2",
      "id": "mistral-7b",
      "notes": "Strong 7B baseline with golden scale calibration enabled",
      "quant": "4bit-ok"
    },
    {
      "context_len": 32000,
      "display_name": "Qwen2.5-7B (Apache-2.0)",
      "failure_law": {
        "lambda": 0.1,
        "tau": 0.3
      },
      "hf_repo": "Qwen/Qwen2.5-7B-Instruct",
      "id": "qwen2.5-7b",
      "notes": "Solid multi-lingual reasoning",
      "quant": "4bit-ok"
    },
    {
      "context_len": 2048,
      "display_name": "Pythia-6.9B (Apache-2.0)",
      "failure_law": {
        "lambda": 0.1,
        "tau": 0.3
      },
      "hf_repo": "EleutherAI/pythia-6.9b",
      "id": "pythia-6.9b",
      "notes": "Calibration/baseline lane",
      "quant": "4bit-ok"
    },
    {
      "context_len": 1024,
      "display_name": "DialoGPT-medium (HF)",
      "failure_law": {
        "lambda": 1.0,
        "tau": 2.083
      },
      "hf_repo": "microsoft/DialoGPT-medium",
      "id": "dialogpt-medium",
      "notes": "Lightweight full-grad/logit node for consensus",
      "quant": "fp32"
    },
    {
      "context_len": 8192,
      "display_name": "Ollama Mistral:7B (logits-only)",
      "failure_law": {
        "lambda": 0.1,
        "tau": 0.3
      },
      "hf_repo": "ollama/mistral:7b",
      "id": "ollama-mistral-7b",
      "notes": "Edge-friendly; top-k logprobs via Ollama for diagonal Fisher",
      "quant": "ollama"
    }
  ]
}